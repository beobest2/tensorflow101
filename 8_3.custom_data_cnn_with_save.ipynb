{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "#%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Modify !!! #############\n",
    "save_filename = 'jwlee.ckpt'\n",
    "############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "tfrecord_train = 'fashion_train.tfrecord'\n",
    "tfrecord_val = 'fashion_val.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "n_train = 50000\n",
    "n_val = 10000\n",
    "n_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue, n_batch):\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={            \n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    \n",
    "    # Convert from a scalar string tensor\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)        \n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    image = tf.reshape(image, [img_height, img_width, 1])    \n",
    "    \n",
    "    images, labels = tf.train.batch([image, label_onehot],\n",
    "                                           batch_size=n_batch,\n",
    "                                           capacity=10000,\n",
    "                                           num_threads=4)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, img_height, img_width, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=X, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=drop1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=drop2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(drop3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=drop4, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = os.path.join(cwd, '..', tfrecord_dir, tfrecord_train)\n",
    "val_path = os.path.join(cwd, '..', tfrecord_dir, tfrecord_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([train_path], num_epochs=training_epochs)\n",
    "image_batch, label_batch = read_and_decode(filename_queue, batch_size)\n",
    "filename_queue_val = tf.train.string_input_producer([val_path], num_epochs=training_epochs)\n",
    "image_val, label_val = read_and_decode(filename_queue_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_var = [X, Y, is_train, logits, accuracy]\n",
    "tf.add_to_collection('train_var', train_var[0])\n",
    "tf.add_to_collection('train_var', train_var[1])\n",
    "tf.add_to_collection('train_var', train_var[2])\n",
    "tf.add_to_collection('train_var', train_var[3])\n",
    "tf.add_to_collection('train_var', train_var[4])\n",
    "saver = tf.train.Saver()\n",
    "##saver.export_meta_graph(os.path.join(cur_dir, 'checkpoints', 'mnist_ckpt.meta'), collection_list=['train_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                      tf.local_variables_initializer())\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.558233670 train accuracy =  0.79436 validation accuracy =  0.87260\n",
      "Epoch: 0002 cost = 0.371824895 train accuracy =  0.86396 validation accuracy =  0.88220\n",
      "Epoch: 0003 cost = 0.323153757 train accuracy =  0.88138 validation accuracy =  0.88870\n",
      "Epoch: 0004 cost = 0.294441740 train accuracy =  0.89188 validation accuracy =  0.89600\n",
      "Epoch: 0005 cost = 0.273505639 train accuracy =  0.89906 validation accuracy =  0.90090\n",
      "Epoch: 0006 cost = 0.254130315 train accuracy =  0.90570 validation accuracy =  0.91080\n",
      "Epoch: 0007 cost = 0.240963971 train accuracy =  0.91034 validation accuracy =  0.91460\n",
      "Epoch: 0008 cost = 0.227920539 train accuracy =  0.91488 validation accuracy =  0.90950\n",
      "Epoch: 0009 cost = 0.217932968 train accuracy =  0.91980 validation accuracy =  0.91710\n",
      "Epoch: 0010 cost = 0.209030790 train accuracy =  0.92104 validation accuracy =  0.91940\n",
      "Epoch: 0011 cost = 0.198313599 train accuracy =  0.92560 validation accuracy =  0.91860\n",
      "Epoch: 0012 cost = 0.195518554 train accuracy =  0.92732 validation accuracy =  0.92490\n",
      "Epoch: 0013 cost = 0.185970656 train accuracy =  0.93062 validation accuracy =  0.92270\n",
      "Epoch: 0014 cost = 0.182113410 train accuracy =  0.93198 validation accuracy =  0.92540\n",
      "Epoch: 0015 cost = 0.175544667 train accuracy =  0.93444 validation accuracy =  0.92680\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_val_acc = 0.\n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_val = int(n_val / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = sess.run([image_batch, label_batch])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        acc, c, _ = sess.run([accuracy, cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "        \n",
    "    for i in range(total_batch_val):\n",
    "        batch_xs, batch_ys = sess.run([image_val, label_val])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_val_acc += acc / total_batch_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'train accuracy = ', \n",
    "         '{:.5f}'.format(avg_train_acc), 'validation accuracy = ', '{:.5f}'.format(avg_val_acc))\n",
    "\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Work\\\\FC_TF_course\\\\..\\\\checkpoints\\\\jwlee3.ckpt'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, os.path.join(cwd, '..', 'checkpoints', save_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
