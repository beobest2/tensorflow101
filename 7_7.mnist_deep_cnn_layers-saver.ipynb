{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "cur_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=X_img, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=drop1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=drop2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(drop3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=drop4, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_var = [X, Y, is_train, logits, accuracy]\n",
    "#tf.add_to_collection('train_var', train_var[0])\n",
    "#tf.add_to_collection('train_var', train_var[1])\n",
    "#tf.add_to_collection('train_var', train_var[2])\n",
    "#tf.add_to_collection('train_var', train_var[3])\n",
    "#tf.add_to_collection('train_var', train_var[4])\n",
    "saver = tf.train.Saver()\n",
    "##saver.export_meta_graph(os.path.join(cur_dir, 'checkpoints', 'mnist_ckpt.meta'), collection_list=['train_var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.295454224\n",
      "Epoch: 0002 cost = 0.088863612\n",
      "Epoch: 0003 cost = 0.067647892\n",
      "Epoch: 0004 cost = 0.055628284\n",
      "Epoch: 0005 cost = 0.048756162\n",
      "Epoch: 0006 cost = 0.045895589\n",
      "Epoch: 0007 cost = 0.043248225\n",
      "Epoch: 0008 cost = 0.039237664\n",
      "Epoch: 0009 cost = 0.037732987\n",
      "Epoch: 0010 cost = 0.034964766\n",
      "Epoch: 0011 cost = 0.031873161\n",
      "Epoch: 0012 cost = 0.030457574\n",
      "Epoch: 0013 cost = 0.029534908\n",
      "Epoch: 0014 cost = 0.030218933\n",
      "Epoch: 0015 cost = 0.028181093\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Work\\\\FC_TF_course\\\\checkpoints\\\\mnist_save.ckpt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, os.path.join(cur_dir, 'checkpoints', 'mnist_save.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Evaluates\n",
      "-------------------------------\n",
      "Train Accuracy: 0.99787\n",
      "Test Accuracy: 0.99320\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X_sample, y_sample, batch_size=100):\n",
    "    \"\"\"Run a minibatch accuracy op\"\"\"\n",
    "\n",
    "    N = X_sample.shape[0]\n",
    "    correct_sample = 0\n",
    "\n",
    "    for i in range(0, N, batch_size):\n",
    "        X_batch = X_sample[i: i + batch_size]\n",
    "        y_batch = y_sample[i: i + batch_size]\n",
    "        N_batch = X_batch.shape[0]\n",
    "\n",
    "        feed = {\n",
    "            X: X_batch,\n",
    "            Y: y_batch,\n",
    "            is_train: False\n",
    "        }\n",
    "\n",
    "        correct_sample += sess.run(accuracy, feed_dict=feed) * N_batch\n",
    "\n",
    "    return correct_sample / N\n",
    "\n",
    "print(\"\\nAccuracy Evaluates\")\n",
    "print(\"-------------------------------\")\n",
    "print('Train Accuracy:', '{:.5f}'.format(evaluate(mnist.train.images, mnist.train.labels)))\n",
    "print('Test Accuracy:', '{:.5f}'.format(evaluate(mnist.test.images, mnist.test.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    }
   ],
   "source": [
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wG1pUyLvuBRzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18ce5fd55c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
