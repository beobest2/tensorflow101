{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    initial = tf.random_normal(shape, stddev=0.1)\n",
    "    #return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size=[3,3], strides=[1,1], activation='Relu', padding='SAME'):\n",
    "    w_shape = kernel_size + [int(inputs.get_shape()[3])] + [filters]    \n",
    "    w = weight_variable(w_shape)    \n",
    "    strides = [1] + strides + [1]\n",
    "    layer = tf.nn.conv2d(inputs, w, strides=strides, padding=padding)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(inputs, pool_size=[2,2], strides=[2,2], padding='SAME'):\n",
    "    ksize = [1] + pool_size + [1]\n",
    "    strides = [1] + strides + [1]\n",
    "    return tf.nn.max_pool(inputs, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs):\n",
    "    in_shape = inputs.get_shape()\n",
    "    return tf.reshape(inputs, [-1, int(in_shape[1]) * int(in_shape[2]) * int(in_shape[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(inputs, units, activation='None'):\n",
    "    w_shape = [int(inputs.get_shape()[1]), units]    \n",
    "    w = weight_variable(w_shape)\n",
    "    b = bias_variable([units])\n",
    "    layer = tf.nn.bias_add(tf.matmul(inputs, w), b)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(inputs, rate=0.5, training=False):\n",
    "    keep_prob = 1. - rate\n",
    "    layer = tf.cond(training, lambda: tf.nn.dropout(inputs, keep_prob=keep_prob), lambda: inputs)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = conv2d(X_img, 32)\n",
    "pool1 = maxpool2d(conv1)\n",
    "drop1 = dropout(pool1, rate=0.3, training=is_train)\n",
    "#drop1 = tf.nn.dropout(pool1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = conv2d(drop1, 64)\n",
    "pool2 = maxpool2d(conv2)\n",
    "drop2 = dropout(pool2, rate=0.3, training=is_train)\n",
    "#drop2 = tf.nn.dropout(pool2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv3 = conv2d(drop2, 128)\n",
    "pool3 = maxpool2d(conv3)\n",
    "drop3 = dropout(pool3, rate=0.3, training=is_train)\n",
    "#drop3 = tf.nn.dropout(pool3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = flatten(drop3)\n",
    "dense4 = dense(flat3, 625, activation='Relu')\n",
    "drop4 = dropout(dense4, rate=0.7, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = dense(drop4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.984636472\n",
      "Epoch: 0002 cost = 0.228994836\n",
      "Epoch: 0003 cost = 0.158217485\n",
      "Epoch: 0004 cost = 0.121816993\n",
      "Epoch: 0005 cost = 0.102010371\n",
      "Epoch: 0006 cost = 0.090424270\n",
      "Epoch: 0007 cost = 0.083149526\n",
      "Epoch: 0008 cost = 0.073801431\n",
      "Epoch: 0009 cost = 0.068416812\n",
      "Epoch: 0010 cost = 0.064662384\n",
      "Epoch: 0011 cost = 0.056880960\n",
      "Epoch: 0012 cost = 0.055230039\n",
      "Epoch: 0013 cost = 0.053006558\n",
      "Epoch: 0014 cost = 0.049429656\n",
      "Epoch: 0015 cost = 0.044798250\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9935\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, is_train: False}))\n",
    "      #X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f4004366a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
