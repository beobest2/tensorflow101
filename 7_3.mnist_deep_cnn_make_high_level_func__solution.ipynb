{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    #initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    initial = tf.random_normal(shape, stddev=0.1)\n",
    "    #return tf.get_variable(name, shape=shape, initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.random_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size=[3,3], strides=[1,1], activation='Relu', padding='SAME'):\n",
    "    w_shape = kernel_size + [int(inputs.get_shape()[3])] + [filters]    \n",
    "    w = weight_variable(w_shape)    \n",
    "    strides = [1] + strides + [1]\n",
    "    layer = tf.nn.conv2d(inputs, w, strides=strides, padding=padding)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(inputs, pool_size=[2,2], strides=[2,2], padding='SAME'):\n",
    "    ksize = [1] + pool_size + [1]\n",
    "    strides = [1] + strides + [1]\n",
    "    return tf.nn.max_pool(inputs, ksize=ksize, strides=strides, padding=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(inputs):\n",
    "    in_shape = inputs.get_shape()\n",
    "    return tf.reshape(inputs, [-1, int(in_shape[1]) * int(in_shape[2]) * int(in_shape[3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense(inputs, units, activation='None'):\n",
    "    w_shape = [int(inputs.get_shape()[1]), units]    \n",
    "    w = weight_variable(w_shape)\n",
    "    b = bias_variable([units])\n",
    "    layer = tf.nn.bias_add(tf.matmul(inputs, w), b)\n",
    "    if activation == 'Relu':        \n",
    "        layer = tf.nn.relu(layer)\n",
    "    elif activation == 'Sigmoid':\n",
    "        layer = tf.nn.sigmoid(layer)\n",
    "    else:\n",
    "        layer = layer    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout(inputs, rate=0.5, training=False):\n",
    "    keep_prob = 1. - rate\n",
    "    layer = tf.cond(training, lambda: tf.nn.dropout(inputs, keep_prob=keep_prob), lambda: inputs)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train-images-idx3-ubyte.gz\n",
      "Extracting ../data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(tf.bool)\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv1 = conv2d(X_img, 32)\n",
    "pool1 = maxpool2d(conv1)\n",
    "drop1 = dropout(pool1, rate=0.3, training=is_train)\n",
    "#drop1 = tf.nn.dropout(pool1, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = conv2d(drop1, 64)\n",
    "pool2 = maxpool2d(conv2)\n",
    "drop2 = dropout(pool2, rate=0.3, training=is_train)\n",
    "#drop2 = tf.nn.dropout(pool2, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv3 = conv2d(drop2, 128)\n",
    "pool3 = maxpool2d(conv3)\n",
    "drop3 = dropout(pool3, rate=0.3, training=is_train)\n",
    "#drop3 = tf.nn.dropout(pool3, keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat3 = flatten(drop3)\n",
    "dense4 = dense(flat3, 625, activation='Relu')\n",
    "drop4 = dropout(dense4, rate=0.5, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = dense(drop4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.733945309\n",
      "Epoch: 0002 cost = 0.171566382\n",
      "Epoch: 0003 cost = 0.122186193\n",
      "Epoch: 0004 cost = 0.094814239\n",
      "Epoch: 0005 cost = 0.080116983\n",
      "Epoch: 0006 cost = 0.069865442\n",
      "Epoch: 0007 cost = 0.062134881\n",
      "Epoch: 0008 cost = 0.057660156\n",
      "Epoch: 0009 cost = 0.053155154\n",
      "Epoch: 0010 cost = 0.048733571\n",
      "Epoch: 0011 cost = 0.045139475\n",
      "Epoch: 0012 cost = 0.042168387\n",
      "Epoch: 0013 cost = 0.041988781\n",
      "Epoch: 0014 cost = 0.036946269\n",
      "Epoch: 0015 cost = 0.035003793\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, is_train: True}\n",
    "        #feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9949\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, is_train: False}))\n",
    "      #X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1.}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], is_train: False}))\n",
    "    #tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1.}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndjweWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e34c3246a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
