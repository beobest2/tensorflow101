{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = 64\n",
    "img_height = 64\n",
    "\n",
    "tfrecord_train = 'train.tfrecord'\n",
    "tfrecord_test = 'test.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 100\n",
    "batch_size = 10\n",
    "n_train = 160\n",
    "n_test = 40\n",
    "n_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_decode(filename_queue, n_batch):\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    \n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={            \n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64)\n",
    "        })\n",
    "    \n",
    "    # Convert from a scalar string tensor\n",
    "    image = tf.decode_raw(features['image'], tf.uint8)        \n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label_onehot = tf.one_hot(label, depth=n_class)\n",
    "    \n",
    "    image = tf.reshape(image, [img_height, img_width, 3])    \n",
    "    \n",
    "    images, labels = tf.train.batch([image, label_onehot],\n",
    "                                           batch_size=n_batch,\n",
    "                                           capacity=10000,\n",
    "                                           num_threads=4)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, img_height, img_width, 3])\n",
    "Y = tf.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#L1 ImgIn shape=(?, 64, 64, 3)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 3, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# L2 ImgIn shape=(?, 32, 32, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "# L3 ImgIn shape=(?, 16, 16, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 8 * 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# L4 FC 8x8x128 inputs -> 512 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 8 * 8, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "# L5 Final FC 512 inputs -> 2 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, n_class],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([n_class]))\n",
    "logits = tf.matmul(L4, W5) + b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "train_path = os.path.join(cwd, tfrecord_dir, tfrecord_train)\n",
    "test_path = os.path.join(cwd, tfrecord_dir, tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([train_path], num_epochs=training_epochs)\n",
    "image_batch, label_batch = read_and_decode(filename_queue, batch_size)\n",
    "filename_queue_test = tf.train.string_input_producer([test_path], num_epochs=1)\n",
    "image_test, label_test = read_and_decode(filename_queue_test, n_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.group(tf.global_variables_initializer(),\n",
    "                      tf.local_variables_initializer())\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 cost = 0.946553156\n",
      "Epoch: 0002 cost = 0.793260776\n",
      "Epoch: 0003 cost = 0.774894100\n",
      "Epoch: 0004 cost = 0.797910705\n",
      "Epoch: 0005 cost = 0.758484304\n",
      "Epoch: 0006 cost = 0.763750713\n",
      "Epoch: 0007 cost = 0.799558040\n",
      "Epoch: 0008 cost = 0.770335522\n",
      "Epoch: 0009 cost = 0.762408720\n",
      "Epoch: 0010 cost = 0.730643507\n",
      "Epoch: 0011 cost = 0.865094427\n",
      "Epoch: 0012 cost = 0.765212599\n",
      "Epoch: 0013 cost = 0.798024461\n",
      "Epoch: 0014 cost = 0.737989601\n",
      "Epoch: 0015 cost = 0.764530282\n",
      "Epoch: 0016 cost = 0.709436145\n",
      "Epoch: 0017 cost = 0.772390585\n",
      "Epoch: 0018 cost = 0.766136998\n",
      "Epoch: 0019 cost = 0.736108653\n",
      "Epoch: 0020 cost = 0.729286881\n",
      "Epoch: 0021 cost = 0.703121480\n",
      "Epoch: 0022 cost = 0.729869016\n",
      "Epoch: 0023 cost = 0.701436047\n",
      "Epoch: 0024 cost = 0.669311460\n",
      "Epoch: 0025 cost = 0.615139045\n",
      "Epoch: 0026 cost = 0.629877109\n",
      "Epoch: 0027 cost = 0.647754641\n",
      "Epoch: 0028 cost = 0.646531584\n",
      "Epoch: 0029 cost = 0.538095472\n",
      "Epoch: 0030 cost = 0.594856504\n",
      "Epoch: 0031 cost = 0.532842956\n",
      "Epoch: 0032 cost = 0.523253303\n",
      "Epoch: 0033 cost = 0.465435291\n",
      "Epoch: 0034 cost = 0.432143171\n",
      "Epoch: 0035 cost = 0.393860100\n",
      "Epoch: 0036 cost = 0.399180838\n",
      "Epoch: 0037 cost = 0.385987178\n",
      "Epoch: 0038 cost = 0.366684509\n",
      "Epoch: 0039 cost = 0.346895469\n",
      "Epoch: 0040 cost = 0.338542645\n",
      "Epoch: 0041 cost = 0.328285038\n",
      "Epoch: 0042 cost = 0.262759693\n",
      "Epoch: 0043 cost = 0.168719877\n",
      "Epoch: 0044 cost = 0.201864640\n",
      "Epoch: 0045 cost = 0.132498820\n",
      "Epoch: 0046 cost = 0.114109722\n",
      "Epoch: 0047 cost = 0.137930728\n",
      "Epoch: 0048 cost = 0.138391215\n",
      "Epoch: 0049 cost = 0.206930629\n",
      "Epoch: 0050 cost = 0.159890744\n",
      "Epoch: 0051 cost = 0.179458534\n",
      "Epoch: 0052 cost = 0.185059687\n",
      "Epoch: 0053 cost = 0.087426977\n",
      "Epoch: 0054 cost = 0.062280067\n",
      "Epoch: 0055 cost = 0.061725678\n",
      "Epoch: 0056 cost = 0.047920145\n",
      "Epoch: 0057 cost = 0.058737716\n",
      "Epoch: 0058 cost = 0.055955801\n",
      "Epoch: 0059 cost = 0.105103728\n",
      "Epoch: 0060 cost = 0.066625003\n",
      "Epoch: 0061 cost = 0.060555959\n",
      "Epoch: 0062 cost = 0.035167857\n",
      "Epoch: 0063 cost = 0.034308080\n",
      "Epoch: 0064 cost = 0.029066337\n",
      "Epoch: 0065 cost = 0.020115436\n",
      "Epoch: 0066 cost = 0.043294854\n",
      "Epoch: 0067 cost = 0.076211526\n",
      "Epoch: 0068 cost = 0.139374911\n",
      "Epoch: 0069 cost = 0.063384885\n",
      "Epoch: 0070 cost = 0.034614050\n",
      "Epoch: 0071 cost = 0.046483948\n",
      "Epoch: 0072 cost = 0.015036490\n",
      "Epoch: 0073 cost = 0.027597304\n",
      "Epoch: 0074 cost = 0.030401621\n",
      "Epoch: 0075 cost = 0.036541227\n",
      "Epoch: 0076 cost = 0.018411367\n",
      "Epoch: 0077 cost = 0.010640037\n",
      "Epoch: 0078 cost = 0.036434727\n",
      "Epoch: 0079 cost = 0.010554420\n",
      "Epoch: 0080 cost = 0.026933726\n",
      "Epoch: 0081 cost = 0.018581791\n",
      "Epoch: 0082 cost = 0.073756854\n",
      "Epoch: 0083 cost = 0.020889414\n",
      "Epoch: 0084 cost = 0.046048338\n",
      "Epoch: 0085 cost = 0.015852550\n",
      "Epoch: 0086 cost = 0.008726361\n",
      "Epoch: 0087 cost = 0.012490341\n",
      "Epoch: 0088 cost = 0.026883091\n",
      "Epoch: 0089 cost = 0.028059590\n",
      "Epoch: 0090 cost = 0.087593491\n",
      "Epoch: 0091 cost = 0.050434406\n",
      "Epoch: 0092 cost = 0.021278244\n",
      "Epoch: 0093 cost = 0.008651808\n",
      "Epoch: 0094 cost = 0.130275234\n",
      "Epoch: 0095 cost = 0.067918571\n",
      "Epoch: 0096 cost = 0.036613244\n",
      "Epoch: 0097 cost = 0.018937969\n",
      "Epoch: 0098 cost = 0.014361738\n",
      "Epoch: 0099 cost = 0.016106306\n",
      "Epoch: 0100 cost = 0.006620884\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(n_train / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = sess.run([image_batch, label_batch])\n",
    "        batch_xs = batch_xs/255.\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n",
      "Label:  [0]\n",
      "Prediction:  [1]\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "test_xs, test_ys = sess.run([image_test, label_test])\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: test_xs, Y: test_ys, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, n_test - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(test_ys[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: test_xs[r:r + 1], keep_prob: 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
